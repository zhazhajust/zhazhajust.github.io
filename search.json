[{"title":"Podman Compose 容器无法访问外网：Rootless 网络原理与解决方案（pasta vs slirp4netns）","url":"/2026/01/02/rootless_network/","content":"\n> 现象：同一份 `docker-compose.yml`，用 **Docker Compose** 启动后容器能访问外网；用 **Podman Compose** 启动后容器访问外网失败。  \n> 结论：通常不是业务问题，而是 **Podman Rootless 网络实现与 Docker Rootful NAT Bridge 的差异**导致。\n\n## 一、现象与定位\n\n我这边首先用一条命令确认 Podman 的运行模式与网络后端：\n\n```bash\npodman info --format '{{.Host.Security.Rootless}} {{.Host.NetworkBackend}}'\n````\n\n输出：\n\n```text\ntrue netavark\n```\n\n含义：\n\n* `true`：说明是 **rootless（非 root）** 模式在运行容器。\n* `netavark`：Podman 的网络后端（负责创建网络等）。\n\n**关键点**：Docker 常见是 rootful + bridge NAT，Podman rootless 则不能直接使用内核层面的 iptables/nftables NAT 规则，需要走 rootless 专用的网络方案（如 `pasta` / `slirp4netns`）。\n\n---\n\n## 二、为什么 Docker 能外网，Podman rootless 却不行？\n\n### 1）NAT 出口是什么？\n\n容器通常拿到的是私网地址（例如 `10.x` / `172.16-31.x` / `192.168.x`）。这些地址在公网是**不可路由**的：\n\n* 容器发起公网请求时，源 IP 是私网地址；\n* 公网服务器回包时不知道该把响应发回哪里（私网地址在公网不可达）。\n\n因此需要一个“出口”把私网源地址**改写**成宿主机可路由的地址，并维护映射关系，让回包能正确回到容器。这种机制就是 **NAT（Network Address Translation）**，对应的位置就是 **NAT 出口**。\n\n简化理解：\n\n* 出去：`容器私网 IP:端口` → 改写成 `宿主机对外 IP:端口`\n* 回来：根据映射表把回包还原 → 转发回容器\n\nDocker 默认 bridge 网络会配合内核 NAT（iptables/nftables）实现这一点，所以“出公网”通常很稳。\n\n### 2）rootless 的限制：没有特权做系统级 NAT\n\n在 rootless 模式下，Podman 运行在普通用户权限，**不能随意修改系统的 iptables/nftables 规则**，于是需要使用 rootless 专用的网络方案来实现联网。\n\nPodman rootless 常见两种网络实现：\n\n* `pasta`：尽量让容器“像在宿主机网络上一样”，但在某些环境里（多网卡、VPN、策略路由、默认路由复杂等）可能出现出口选择/回程路径问题；并且其行为与 Docker 的经典 NAT bridge 不完全一致。\n* `slirp4netns`：通过用户态方式提供一个更“传统”的 **NAT 出口模型**（更接近 Docker bridge + NAT 的体验），很多场景下对“访问外网（HTTP/HTTPS）”更稳定。\n\n---\n\n## 三、排查思路（快速判断是路由问题还是 DNS 问题）\n\n进容器测试：\n\n```bash\npodman exec -it <容器名> sh -lc '\nip route;\ncat /etc/resolv.conf;\ncurl -I https://1.1.1.1 || true;\ncurl -I https://example.com || true\n'\n```\n\n解释：\n\n* `curl https://1.1.1.1` 也失败：多半是 **路由/NAT/出口**问题。\n* `1.1.1.1` 通但 `example.com` 不通：多半是 **DNS** 问题（可考虑在 compose 显式配置 `dns:` 或检查 base 配置是否在 Podman 下合并生效）。\n\n---\n\n## 四、最终解决方案：切换 rootless 默认网络为 slirp4netns\n\n编辑配置文件：\n\n`~/.config/containers/containers.conf`\n\n加入：\n\n```ini\n[network]\ndefault_rootless_network_cmd = \"slirp4netns\"\n```\n\n重建容器：\n\n```bash\npodman compose down\npodman compose up -d\n```\n\n**结果**：容器恢复可访问外网。\n\n### 为什么这个改动有效？\n\n因为它把 rootless 容器的出网方式切换成 `slirp4netns` 的用户态 NAT 模型，提供更明确的“虚拟网关 + NAT 出口”，从而让私网地址的容器流量能稳定转换并访问公网（更接近 Docker 默认 bridge 的行为）。\n\n---\n\n## 五、备选方案\n\n### 方案 A：直接用 rootful 运行（更接近 Docker）\n\n如果环境允许（并且你希望网络行为尽量和 Docker 一致）：\n\n```bash\nsudo podman compose up -d\n```\n\nrootful 下可以使用更标准的内核桥接与 NAT 能力。\n\n### 方案 B：保持 pasta，但指定出口接口（适合复杂路由）\n\n如果你必须使用 `pasta`（例如你更在意性能、或需要某些 pasta 特性），可以考虑指定正确的出公网接口，避免出口选择错误（多网卡/VPN/策略路由环境尤其重要）。\n\n---\n\n## 六、总结\n\n* **Docker Compose 能外网**：典型是 rootful + bridge + 内核 NAT，出网路径明确。\n* **Podman Compose 外网失败（常见）**：rootless 模式下网络实现不同，默认方案在某些环境里不稳定或行为不等价。\n* **最快/最稳的修复**：rootless 切换默认网络为 `slirp4netns`：\n\n```ini\n[network]\ndefault_rootless_network_cmd = \"slirp4netns\"\n```\n\n如果你也遇到“Docker 能联网但 Podman 不行”的情况，优先检查是不是 rootless，并用以上方式切换网络实现，通常能立刻解决。\n\n```\n::contentReference[oaicite:0]{index=0}\n```\n","tags":["podman","docker","compose","linux","network","rootless"],"categories":["运维","容器"]},{"title":"Linux cgroup 实现 SSH 用户资源限制指南","url":"/2025/12/21/linux-cgroup-ssh-limit/","content":"\n# Linux cgroup 实现 SSH 用户资源限制指南\n\n## 概述\n\nLinux 控制组（cgroup）是内核提供的资源管理机制，可用于限制、隔离和监控进程组（如用户会话）的资源使用。通过 systemd 与 cgroup 结合，我们可以为 SSH 登录用户设置公平的资源配额，避免单个用户过度占用 CPU、内存等系统资源，提升多用户环境的稳定性。本指南以实际脚本为例，逐步讲解配置方法。\n\n## 环境准备\n\n- **系统要求**：Linux 内核 ≥ 4.15（支持 cgroup v2），使用 systemd 作为初始化系统。\n- **权限需求**：所有操作需 `sudo` 权限。\n\n---\n\n## 配置步骤\n\n### 1. 清理现有配置\n\n为避免残留配置干扰，首先清理旧配置：\n\n```bash\n#!/bin/bash\n# 清理现有配置\nsudo rm -rf /etc/systemd/system/user.slice.d/\nsudo rm -rf /etc/systemd/system/user-*.slice.d/\n```\n\n**作用**：删除可能存在的旧切片配置目录，确保配置纯净。\n\n### 2. 设置全局资源限制\n\n创建全局切片配置，限制所有用户会话的总资源上限：\n\n```bash\n# 使用正确的配置文件方式\nsudo mkdir -p /etc/systemd/system/user.slice.d/\nsudo tee /etc/systemd/system/user.slice.d/global.conf << 'EOF'\n[Slice]\nCPUQuota=400%     # 限制所有用户会话合计最多使用 400% CPU（即 4 核）\nMemoryMax=16G     # 限制所有用户会话合计最多使用 16GB 内存\nEOF\n```\n\n**参数说明**：\n- `CPUQuota=400%`：表示所有用户进程共享的 CPU 时间上限为 4 个核心的 100% 占用。\n- `MemoryMax=16G`：全局内存使用硬限制。\n\n### 3. 设置单用户默认限制\n\n创建用户级模板，为每个登录用户分配独立配额：\n\n```bash\n# 创建用户默认模板（用户登录时自动应用）\nsudo mkdir -p /etc/systemd/system/user@.service.d/\nsudo tee /etc/systemd/system/user@.service.d/limit.conf << 'EOF'\n[Service]\nCPUWeight=100     # CPU 相对权重（默认 100，值越高优先级越高）\nMemoryMax=4G      # 单用户内存使用上限为 4GB\nEOF\n```\n\n**参数说明**：\n- `CPUWeight=100`：基于 CPU 时间分配的权重（范围 1–10000），值越大获得的 CPU 时间越多。\n- `MemoryMax=4G`：单用户内存硬限制，超限时进程会被终止。\n\n### 4. 重载并生效配置\n\n使新配置生效：\n\n```bash\n# 重载配置\nsudo systemctl daemon-reload\n\n# 可选：重启用户切片（或重启系统）\n# sudo systemctl restart user.slice\n```\n\n**注意**：配置立即生效，但已登录用户需重新登录才能应用新限制。\n\n---\n\n## 验证资源配置\n\n使用以下脚本检查当前 cgroup 设置：\n\n```bash\n#!/bin/bash\nfind /sys/fs/cgroup/user.slice -name \"cpu.max\" -type f -print0 |\nwhile IFS= read -r -d '' file; do\n  user_dir=$(dirname \"$file\")\n  cpu_limit=$(cat \"$file\")\n  mem_file=\"$user_dir/memory.max\"\n  \n  if [ -f \"$mem_file\" ]; then\n    mem_limit=$(cat \"$mem_file\")\n  else\n    mem_limit=\"未设置\"\n  fi\n  \n  echo \"$user_dir: CPU=$cpu_limit, Memory=$mem_limit\"\ndone\n```\n\n**输出示例**：\n```\n/user.slice/user-1000.slice: CPU=max 100000, Memory=4294967296\n```\n- `CPU=max 100000`：表示 CPU 时间限制为 100000 微秒/周期（即 100% 核心）。\n- `Memory=4294967296`：内存限制字节数（此处 4GB）。\n\n---\n\n## 注意事项\n\n1. **资源分配公平性**：`CPUWeight` 适用于 CPU 竞争场景，确保高权重用户获得更多资源。\n2. **内存限制**：`MemoryMax` 为硬限制，超限时进程会触发 OOM Killer。\n3. **持久化配置**：通过 systemd 配置可持久化，重启后依旧有效。\n4. **调试建议**：若配置未生效，检查 `systemd-cgls` 或 `cat /sys/fs/cgroup/user.slice/*/cpu.max` 验证。\n\n## 总结\n\n通过 cgroup 和 systemd 的集成，我们可以高效管理多用户环境下的资源分配。本指南提供的脚本可直接用于生产环境，但需根据实际硬件资源调整参数值。合理配置资源限制能显著提升系统稳定性，避免资源争夺导致的性能下降。\n\n\n```bash\n#!/bin/bash\n# 1. 清理现有配置\nsudo rm -rf /etc/systemd/system/user.slice.d/\nsudo rm -rf /etc/systemd/system/user-*.slice.d/\nsudo rm -rf /etc/systemd/system/user@.service.d/\n\n# 2. 使用正确的配置文件方式\nsudo mkdir -p /etc/systemd/system/user.slice.d/\nsudo tee /etc/systemd/system/user.slice.d/global.conf << 'EOF'\n[Slice]\n# CPUQuota=400%\n# MemoryMax=16G\nCPUQuota=\nMemoryMax=\nEOF\n\n# 3. 创建用户默认模板（这会在用户登录时自动应用）\nsudo mkdir -p /etc/systemd/system/user@.service.d/\nsudo tee /etc/systemd/system/user@.service.d/limit.conf << 'EOF'\n[Service]\n# CPUWeight=100\nCPUQuota=100%\nMemoryMax=4G\nEOF\n\n# 给 root 的 slice 覆盖掉限制\nsudo mkdir -p /etc/systemd/system/user-0.slice.d/\n\nsudo tee /etc/systemd/system/user-0.slice.d/override.conf <<'EOF'\n[Slice]\nCPUQuota=\nMemoryMax=\nEOF\n\n# 给特定用户 ID（例如 990）的 slice 覆盖掉限制\nslurm_id=$(id -u slurm)\nsudo mkdir -p /etc/systemd/system/user-$slurm_id.slice.d/\n\nsudo tee /etc/systemd/system/user-$slurm_id.slice.d/override.conf <<'EOF'\n[Slice]\nCPUQuota=\nMemoryMax=\nCPUWeight=\nEOF\n\n# 4. 重载配置\nsudo systemctl daemon-reload\n\n# # 5. 重启用户切片（或重启系统）\n# sudo systemctl restart user.slice\nsudo systemctl restart systemd-logind\n```\n---\n\n> 本文仅用于教育目的，操作前请备份重要数据。建议在测试环境验证后再部署到生产系统。","tags":["Linux","cgroup","资源管理"]},{"title":"NVIDIA驱动和CUDA安装脚本 for CentOS Stream 9","url":"/2025/12/21/install_driver/","content":"\n安装好centos9系统后，装好显卡，配置好网络环境。安装好NVIDIA驱动，然后安装CUDA工具包。以下是完整的安装脚本：\n\n```bash\n#!/bin/bash\n\n# NVIDIA驱动和CUDA安装脚本 for CentOS Stream 9\n# 作者: Assistant\n# 说明: 此脚本用于在CentOS Stream 9上安装NVIDIA驱动和CUDA工具包\n\nset -e  # 遇到错误立即退出\n\n# ========== 配置部分 ==========\nreadonly RED='\\033[0;31m'\nreadonly GREEN='\\033[0;32m'\nreadonly YELLOW='\\033[1;33m'\nreadonly BLUE='\\033[0;34m'\nreadonly NC='\\033[0m' # No Color\nreadonly ORIG_TARGET=$(systemctl get-default)\n\nreadonly NVIDIA_DRIVER_URL=\"https://download.nvidia.com/XFree86/Linux-x86_64/580.105.08/NVIDIA-Linux-x86_64-580.105.08.run\"\nreadonly NVIDIA_DRIVER_FILE=\"./NVIDIA-Linux-x86_64-580.105.08.run\"\nreadonly CUDA_VERSION=\"12.4.0\"\nreadonly CUDA_INSTALLER=\"cuda_${CUDA_VERSION}_550.54.14_linux.run\"\nreadonly CUDA_URL=\"https://developer.download.nvidia.com/compute/cuda/${CUDA_VERSION}/local_installers/${CUDA_INSTALLER}\"\n\n# ========== 日志函数 ==========\nlog_info() {\n    echo -e \"${GREEN}[INFO]${NC} $1\"\n}\n\nlog_warn() {\n    echo -e \"${YELLOW}[WARN]${NC} $1\"\n}\n\nlog_error() {\n    echo -e \"${RED}[ERROR]${NC} $1\"\n}\n\nlog_step() {\n    echo -e \"${BLUE}[STEP]${NC} $1\"\n}\n\n# ========== 工具函数 ==========\ncheck_root() {\n    if [[ $EUID -ne 0 ]]; then\n        log_error \"此脚本需要root权限运行\"\n        log_info \"请使用: sudo bash $0\"\n        exit 1\n    fi\n}\n\ncheck_nvidia_gpu() {\n    log_step \"1. 检查系统中是否存在NVIDIA GPU...\"\n    if lspci | grep -i nvidia > /dev/null 2>&1; then\n        log_info \"✓ 检测到NVIDIA GPU\"\n        return 0\n    else\n        log_error \"✗ 未检测到NVIDIA GPU\"\n        return 1\n    fi\n}\n\n# ========== 系统配置函数 ==========\nupdate_system() {\n    log_step \"2. 正在更新系统...\"\n    dnf update -y\n    log_info \"✓ 系统更新完成\"\n}\n\nconfigure_repos() {\n    log_step \"3. 配置软件仓库...\"\n    \n    # 更新DNF缓存\n    dnf makecache -y\n    \n    # 启用CRB仓库\n    log_info \"启用CRB仓库...\"\n    dnf config-manager --set-enabled crb\n    \n    # 安装EPEL仓库\n    log_info \"安装EPEL仓库...\"\n    dnf install -y epel-release epel-next-release\n    \n    # 再次更新缓存\n    dnf makecache -y\n    log_info \"✓ 仓库配置完成\"\n}\n\ninstall_dependencies() {\n    log_step \"4. 安装编译依赖...\"\n    \n    # 获取内核版本\n    KERNEL_VERSION=$(uname -r)\n    log_info \"当前内核版本: $KERNEL_VERSION\"\n    \n    # 安装依赖包\n    dnf install -y \\\n        kernel-headers-${KERNEL_VERSION} \\\n        kernel-devel-${KERNEL_VERSION} \\\n        tar \\\n        bzip2 \\\n        make \\\n        automake \\\n        gcc \\\n        gcc-c++ \\\n        pciutils \\\n        elfutils-libelf-devel \\\n        libglvnd-opengl \\\n        libglvnd-glx \\\n        libglvnd-devel \\\n        acpid \\\n        pkgconfig \\\n        dkms \\\n        wget\n    \n    log_info \"✓ 依赖安装完成\"\n}\n\n# ========== Nouveau驱动处理 ==========\ndisable_nouveau() {\n    log_step \"5. 禁用Nouveau驱动...\"\n    \n    # 创建黑名单文件\n    echo 'blacklist nouveau' > /etc/modprobe.d/blacklist-nouveau.conf\n    echo 'options nouveau modeset=0' >> /etc/modprobe.d/blacklist-nouveau.conf\n    \n    # 备份原有initramfs\n    local initramfs_file=\"/boot/initramfs-$(uname -r).img\"\n    if [ -f \"$initramfs_file\" ]; then\n        cp \"$initramfs_file\" \"${initramfs_file}.backup\"\n    fi\n    \n    # 更新initramfs\n    dracut --force\n    \n    log_info \"✓ Nouveau驱动已禁用\"\n}\n\nverify_nouveau_disabled() {\n    log_step \"6. 验证Nouveau驱动状态...\"\n    if lsmod | grep nouveau > /dev/null 2>&1; then\n        log_error \"✗ Nouveau驱动仍在运行\"\n        return 1\n    else\n        log_info \"✓ Nouveau驱动已成功禁用\"\n        return 0\n    fi\n}\n\n# ========== 下载函数 ==========\ndownload_file() {\n    local url=\"$1\"\n    local filename=\"$2\"\n    local description=\"$3\"\n    \n    if [ -f \"$filename\" ]; then\n        log_info \"✓ ${description}文件已存在: $filename\"\n        return 0\n    fi\n    \n    log_info \"正在下载${description}...\"\n    if wget -q --show-progress \"$url\" -O \"$filename\"; then\n        log_info \"✓ ${description}下载完成\"\n        return 0\n    else\n        log_error \"✗ ${description}下载失败\"\n        log_info \"请手动下载: $url\"\n        return 1\n    fi\n}\n\ndownload_nvidia_driver() {\n    log_step \"7. 下载NVIDIA驱动...\"\n    download_file \"$NVIDIA_DRIVER_URL\" \"$NVIDIA_DRIVER_FILE\" \"NVIDIA驱动\"\n}\n\ndownload_cuda() {\n    log_step \"9. 下载CUDA工具包...\"\n    download_file \"$CUDA_URL\" \"$CUDA_INSTALLER\" \"CUDA ${CUDA_VERSION}\"\n}\n\n# ========== NVIDIA驱动安装 ==========\nswitch_to_text_mode() {\n    log_info \"切换到文本模式...\"\n    # systemctl set-default multi-user.target\n    systemctl isolate multi-user.target\n}\n\nrestore_target() {\n  log_info \"恢复默认启动目标: $ORIG_TARGET\"\n  systemctl set-default \"$ORIG_TARGET\"\n}\n\ninstall_nvidia_driver_silent() {\n    log_info \"尝试静默安装NVIDIA驱动...\"\n    \n    if \"$NVIDIA_DRIVER_FILE\" \\\n        --silent \\\n        --no-nouveau-check \\\n        --no-x-check \\\n        --no-questions \\\n        --accept-license \\\n        --disable-nouveau \\\n        --install-libglvnd \\\n        --dkms; then\n        log_info \"✓ NVIDIA驱动安装成功（静默模式）\"\n        return 0\n    fi\n    return 1\n}\n\ninstall_nvidia_driver_interactive() {\n    log_info \"尝试交互模式安装NVIDIA驱动...\"\n    \n    if \"$NVIDIA_DRIVER_FILE\" --no-x-check; then\n        log_info \"✓ NVIDIA驱动安装成功（交互模式）\"\n        return 0\n    fi\n    return 1\n}\n\ninstall_nvidia_driver() {\n    log_step \"8. 安装NVIDIA驱动...\"\n    \n    # 检查驱动文件是否存在\n    if [ ! -f \"$NVIDIA_DRIVER_FILE\" ]; then\n        log_error \"✗ 未找到NVIDIA驱动文件: $NVIDIA_DRIVER_FILE\"\n        return 1\n    fi\n    \n    # 赋予执行权限\n    chmod +x \"$NVIDIA_DRIVER_FILE\"\n    \n    # 切换到文本模式\n    switch_to_text_mode\n    \n    # 安装驱动\n    log_info \"开始安装NVIDIA驱动...\"\n    log_info \"安装过程可能需要几分钟，请耐心等待...\"\n    \n    # 先尝试静默安装\n    if install_nvidia_driver_silent; then\n        return 0\n    fi\n    \n    # 静默安装失败，尝试交互模式\n    log_warn \"静默安装失败，尝试交互模式安装...\"\n    if install_nvidia_driver_interactive; then\n        return 0\n    fi\n    \n    # 两种方式都失败\n    log_error \"✗ NVIDIA驱动安装完全失败\"\n    return 1\n}\n\n# ========== CUDA安装 ==========\ninstall_cuda_toolkit() {\n    log_step \"10. 安装CUDA工具包...\"\n    \n    # 检查CUDA安装文件\n    if [ ! -f \"$CUDA_INSTALLER\" ]; then\n        log_error \"✗ 未找到CUDA安装文件: $CUDA_INSTALLER\"\n        return 1\n    fi\n    \n    # 赋予执行权限\n    chmod +x \"$CUDA_INSTALLER\"\n    \n    # 安装CUDA（不安装驱动）\n    log_info \"开始安装CUDA ${CUDA_VERSION}...\"\n    log_info \"安装过程可能需要几分钟，请耐心等待...\"\n    \n    # 创建安装日志\n    local install_log=\"/tmp/cuda_install.log\"\n    \n    if \"./$CUDA_INSTALLER\" \\\n        --silent \\\n        --toolkit \\\n        --override \\\n        --no-man-page \\\n        --no-opengl-libs \\\n        --installpath=/usr/local/cuda-${CUDA_VERSION} > \"$install_log\" 2>&1; then\n        log_info \"✓ CUDA安装成功\"\n        \n        # 创建符号链接\n        create_cuda_symlink\n        return 0\n    else\n        log_error \"✗ CUDA安装失败\"\n        log_info \"安装日志: $install_log\"\n        return 1\n    fi\n}\n\ncreate_cuda_symlink() {\n    log_info \"创建CUDA符号链接...\"\n    ln -sf /usr/local/cuda-${CUDA_VERSION} /usr/local/cuda\n}\n\n# ========== 环境配置 ==========\nconfigure_environment() {\n    log_step \"11. 配置环境变量...\"\n    \n    # 备份原有配置文件\n    local bashrc_file=\"/etc/bashrc\"\n    if [ -f \"$bashrc_file\" ]; then\n        cp \"$bashrc_file\" \"${bashrc_file}.backup.$(date +%Y%m%d_%H%M%S)\"\n    fi\n    \n    # 添加CUDA环境变量\n    cat >> \"$bashrc_file\" << 'EOF'\n\n# CUDA Environment Variables\nexport PATH=/usr/local/cuda/bin:$PATH\nexport LD_LIBRARY_PATH=/usr/local/cuda/lib64:$LD_LIBRARY_PATH\nexport CUDA_HOME=/usr/local/cuda\nEOF\n    \n    log_info \"✓ 环境变量已配置\"\n    log_info \"请运行 'source /etc/bashrc' 或重新登录使配置生效\"\n}\n\n# ========== 验证安装 ==========\nverify_nvidia_driver() {\n    log_step \"12. 验证NVIDIA驱动安装...\"\n    \n    if command -v nvidia-smi > /dev/null 2>&1; then\n        log_info \"✓ NVIDIA驱动安装成功\"\n        log_info \"显示GPU信息:\"\n        nvidia-smi\n        return 0\n    else\n        log_error \"✗ NVIDIA驱动未正确安装\"\n        return 1\n    fi\n}\n\nverify_cuda_installation() {\n    log_step \"13. 验证CUDA安装...\"\n    \n    if [ -d \"/usr/local/cuda\" ]; then\n        log_info \"✓ CUDA目录存在: /usr/local/cuda\"\n        \n        # 检查nvcc\n        if [ -f \"/usr/local/cuda/bin/nvcc\" ]; then\n            log_info \"✓ nvcc编译器存在\"\n            log_info \"CUDA版本:\"\n            /usr/local/cuda/bin/nvcc --version | grep release\n            return 0\n        else\n            log_error \"✗ nvcc编译器未找到\"\n            return 1\n        fi\n    else\n        log_error \"✗ CUDA目录不存在\"\n        return 1\n    fi\n}\n\n# ========== 清理函数 ==========\ncleanup_installation_files() {\n    log_step \"14. 清理安装文件...\"\n    \n    local files_to_remove=(\n        \"$NVIDIA_DRIVER_FILE\"\n        \"$CUDA_INSTALLER\"\n        \"/tmp/cuda_install.log\"\n    )\n    \n    for file in \"${files_to_remove[@]}\"; do\n        if [ -f \"$file\" ]; then\n            rm -f \"$file\"\n            log_info \"已删除: $file\"\n        fi\n    done\n    \n    log_info \"✓ 清理完成\"\n}\n\n# ========== 重启提示 ==========\nshow_reboot_prompt() {\n    log_step \"15. 安装完成！\"\n    \n    echo \"==========================================\"\n    echo \"安装总结:\"\n    echo \"------------------------------------------\"\n    \n    if verify_nvidia_driver; then\n        echo \"✓ NVIDIA驱动: 已安装\"\n    else\n        echo \"✗ NVIDIA驱动: 安装失败\"\n    fi\n    \n    if verify_cuda_installation; then\n        echo \"✓ CUDA工具包: 已安装\"\n    else\n        echo \"✗ CUDA工具包: 安装失败\"\n    fi\n    \n    echo \"------------------------------------------\"\n    log_warn \"重要提示: 系统需要重启以完成安装\"\n    log_info \"请执行以下命令重启系统:\"\n    echo \"  sudo reboot\"\n    echo \"==========================================\"\n}\n\n# ========== 主安装流程 ==========\nmain_installation() {\n    log_info \"开始NVIDIA驱动和CUDA安装流程...\"\n    echo \"==========================================\"\n    \n    # 前置检查\n    check_root\n    if ! check_nvidia_gpu; then\n        exit 1\n    fi\n    \n    # 系统配置\n    update_system\n    configure_repos\n    install_dependencies\n    \n    # Nouveau驱动处理\n    disable_nouveau\n    if ! verify_nouveau_disabled; then\n        log_warn \"Nouveau驱动可能仍在运行，建议重启后继续\"\n        read -p \"是否继续安装？(y/n): \" -n 1 -r\n        echo\n        if [[ ! $REPLY =~ ^[Yy]$ ]]; then\n            exit 1\n        fi\n    fi\n    \n    # NVIDIA驱动安装\n    if ! download_nvidia_driver; then\n        exit 1\n    fi\n    \n    if ! install_nvidia_driver; then\n        exit 1\n    fi\n    \n    # CUDA安装\n    if ! download_cuda; then\n        exit 1\n    fi\n    \n    if ! install_cuda_toolkit; then\n        exit 1\n    fi\n    \n    # 后续配置\n    configure_environment\n    cleanup_installation_files\n    \n    # 验证和提示\n    verify_nvidia_driver\n    verify_cuda_installation\n    show_reboot_prompt\n    \n    log_info \"安装脚本执行完毕！\"\n}\n\n# ========== 错误处理 ==========\nhandle_error() {\n    local exit_code=$?\n    log_error \"脚本执行失败，退出码: $exit_code\"\n    log_info \"请检查上述错误信息并解决问题后重试\"\n    exit $exit_code\n}\n\n# ========== 脚本入口 ==========\nmain() {\n    # 设置错误处理\n    trap 'handle_error' ERR\n    \n    # 显示欢迎信息\n    echo \"==========================================\"\n    echo \"NVIDIA驱动和CUDA安装脚本\"\n    echo \"适用于: CentOS Stream 9\"\n    echo \"==========================================\"\n    echo \"配置信息:\"\n    echo \"  NVIDIA驱动版本: 580.105.08\"\n    echo \"  CUDA版本: ${CUDA_VERSION}\"\n    echo \"==========================================\"\n    \n    # 确认继续\n    read -p \"是否继续安装？(y/n): \" -n 1 -r\n    echo\n    if [[ ! $REPLY =~ ^[Yy]$ ]]; then\n        log_info \"安装已取消\"\n        exit 0\n    fi\n    \n    # 执行主安装流程\n    main_installation\n}\n\n# 执行主函数\nmain \"$@\"\n```"},{"title":"CentOS Stream 9 单节点 Slurm 集群部署指南","url":"/2025/12/20/slurm-server/","content":"\n本文提供 CentOS Stream 9 单节点环境下安装配置 Slurm（含 slurmctld + slurmd）的标准流程，适用于开发、测试及单机调度场景。\n\n## 一、环境假设与目标架构\n\n### 1. 环境假设\n- 操作系统：CentOS Stream 9（最小化或标准安装）\n- 主机名：node1\n- IP：192.168.1.10（示例）\n- 角色：\n  - 控制节点（Controller）：node1\n  - 计算节点（Compute）：node1\n\n### 2. Slurm 组件\n- slurmctld：控制守护进程\n- slurmd：计算节点守护进程\n- slurmdbd：单机测试通常不需要\n\n## 二、系统基础准备\n\n### 1. 设置主机名与 hosts\n```bash\nhostnamectl set-hostname node1\ncat >> /etc/hosts <<EOF\n# 192.168.1.10   node1\n127.0.0.1   node1\nEOF\n```\n\n### 2. 关闭防火墙（可选，测试环境建议）\n```bash\nsystemctl disable --now firewalld\n```\n\n### 3. 关闭 SELinux（可选，测试环境建议）\n```bash\nsed -i 's/^SELINUX=.*/SELINUX=disabled/' /etc/selinux/config\nsetenforce 0\n```\n\n## 三、安装 Slurm 及依赖\nCentOS 9 官方仓库已包含 Slurm，无需自行编译。\n\n### 1. 安装 EPEL\n```bash\ndnf install -y epel-release\n```\n\n### 2. 安装 Slurm\n```bash\ndnf install -y slurm slurm-slurmd slurm-slurmctld munge\n```\n\n## 四、配置 Munge（Slurm 认证核心）\nSlurm 强依赖 munge 进行节点认证。\n\n### 1. 创建 munge key\n```bash\n/usr/sbin/create-munge-key\n```\n\n### 2. 设置权限（可选，测试环境建议）\n```bash\nchown -R munge:munge /etc/munge /var/lib/munge /var/log/munge\nchmod 400 /etc/munge/munge.key\n```\n\n### 3. 启动 munge\n```bash\nsystemctl enable --now munge\n```\n\n### 4. 验证 munge\n```bash\nmunge -n | unmunge\n```\n正常应看到：\n```\nSTATUS:          Success (0)\n```\n\n## 五、创建 Slurm 用户与目录\n\n### 1. 创建 slurm 用户\n```bash\nuseradd -r -s /sbin/nologin slurm\n```\n\n### 2. 创建必要目录\n```bash\nmkdir -p /var/spool/slurm/{ctld,d}\nmkdir -p /var/log/slurm\nchown -R slurm:slurm /var/spool/slurm /var/log/slurm\n```\n\n## 六、配置 slurm.conf（核心）\n\n### 1. 生成基础模板\n```bash\ncp /etc/slurm/slurm.conf.example /etc/slurm/slurm.conf\n```\n\n### 2. 编辑 /etc/slurm/slurm.conf\n最小可用单机配置示例：\n\nslurm.conf 示例：\n```conf\n############################\n# 基本集群信息\n############################\nClusterName=single_cluster\nSlurmctldHost=node1(127.0.0.1)\nSlurmUser=slurm\nSlurmdUser=root\n\n############################\n# 端口\n############################\nSlurmctldPort=6817\nSlurmdPort=6818\n\n############################\n# 状态与日志\n############################\nStateSaveLocation=/var/spool/slurm/ctld\nSlurmdSpoolDir=/var/spool/slurm/d\nSlurmctldLogFile=/var/log/slurm/slurmctld.log\nSlurmdLogFile=/var/log/slurm/slurmd.log\n\n############################\n# 认证\n############################\nAuthType=auth/munge\nCryptoType=crypto/munge\n\n############################\n# 调度器\n############################\nSchedulerType=sched/backfill\nSchedulerParameters=bf_continue,bf_interval=30\n\n############################\n# 资源选择（关键）\n############################\nSelectType=select/cons_res\nSelectTypeParameters=CR_Core_Memory\n\n############################\n# cgroup（生产必开）\n############################\nProctrackType=proctrack/cgroup\nTaskPlugin=task/cgroup\n# TaskPluginParam=Sched\nJobAcctGatherType=jobacct_gather/cgroup\n\n############################\n# 进程跟踪 / 清理\n############################\nKillOnBadExit=1\nReturnToService=2\n\n############################\n# 超时\n############################\nSlurmctldTimeout=300\nSlurmdTimeout=300\n\n############################\n# 节点定义（按真实资源）\n############################\nNodeName=node1 \\\n  CPUs=56 \\\n  RealMemory=128027 \\\n  Sockets=2 \\\n  CoresPerSocket=28 \\\n  ThreadsPerCore=1 \\\n  Gres=gpu:V100:8 \\\n  State=UNKNOWN\n\nGresTypes=gpu\n\n############################\n# 分区定义\n############################\nPartitionName=debug \\\n  Nodes=node1 \\\n  Default=YES \\\n  MaxTime=1:00:00 \\\n  State=UP\n\nPartitionName=normal \\\n  Nodes=node1 \\\n  MaxTime=7-00:00:00 \\\n  State=UP\n```\n\ncgroup.conf 示例：\n\n```conf\n###\n#\n# Slurm cgroup support configuration file\n#\n# See man slurm.conf and man cgroup.conf for further\n# information on cgroup configuration parameters\n#--\nCgroupMountpoint=/sys/fs/cgroup\nCgroupAutomount=yes\n\nConstrainCores=yes\nConstrainRAMSpace=yes\nConstrainSwapSpace=yes\nConstrainDevices=yes\n\nAllowedRAMSpace=100\nAllowedSwapSpace=0\n\nMaxRAMPercent=98\nMaxSwapPercent=0\n\nMinRAMSpace=30\n```\n\n**注意**：\n- `CPUs` 和 `RealMemory` 根据 `lscpu`、`free -m` 实际调整\n- `NodeName` 必须与 hostname 完全一致\n\n## 七、启动 Slurm 服务\n\n### 1. 启动 slurmctld\n```bash\nsystemctl enable --now slurmctld\n```\n\n### 2. 启动 slurmd\n```bash\nsystemctl enable --now slurmd\n```\n\n## 八、验证 Slurm 状态\n\n### 1. 查看节点状态\n```bash\nsinfo\n```\n期望输出：\n```\nPARTITION AVAIL  TIMELIMIT  NODES  STATE NODELIST\ndebug        up   infinite      1   idle node1\n```\n\n### 2. 查看节点详情\n```bash\nscontrol show node node1\n```\n\n## 九、提交测试任务\n\n### 1. 交互式任务\n```bash\nsrun -n 1 hostname\n```\n\n### 2. 批处理任务\n```bash\ncat > test.sh <<EOF\n#!/bin/bash\n#SBATCH -n 1\n#SBATCH -o test.out\n\nhostname\nsleep 10\nEOF\n\nsbatch test.sh\n```\n\n查看任务：\n```bash\nsqueue\n```\n\n## 十、常见问题排查\n\n### 1. 节点状态为 DOWN\n```bash\nscontrol update NodeName=node1 State=RESUME\n```\n\n### 2. 查看日志\n```bash\njournalctl -u slurmctld -f\njournalctl -u slurmd -f\n```\n\n### 3. Munge 错误\n- 确认 munge 正在运行\n- `/etc/munge/munge.key` 权限必须是 400\n\n## 十一、slurmdbd 需求分析\n\n| 场景             | 是否需要 |\n|------------------|----------|\n| 单机测试         | 否       |\n| 作业计费/统计    | 是       |\n| 多用户审计       | 是       |\n\n如需以下扩展配置，请说明使用场景：\n- CentOS 9 + slurmdbd + MariaDB 配置\n- GPU（NVIDIA）节点配置\n- cgroup 资源隔离详细配置\n- 多节点集群扩展方案\n\n## 十二、GPU 配置（V100 示例）\n\n### 1. 确认 GPU 设备\n```bash\nls -l /dev/nvidia*\n```\n输出示例：\n```\n/dev/nvidia0\n/dev/nvidia1\n/dev/nvidiactl\n/dev/nvidia-uvm\n```\n\n### 2. 配置 gres.conf\n```bash\nvi /etc/slurm/gres.conf\n```\n示例（2 × V100）：\n```conf\nNodeName=node1 Name=gpu Type=V100 File=/dev/nvidia0\nNodeName=node1 Name=gpu Type=V100 File=/dev/nvidia1\n```\n\n**要点**：\n- `Type=V100` 是 `--gres=gpu:V100:x` 参数的关键\n- `NodeName` 必须和 slurm.conf 完全一致\n\n### 3. 修改 slurm.conf\n在节点定义中添加 GPU 资源：\n```conf\nNodeName=node1 \\\n  CPUs=64 \\\n  RealMemory=125000 \\\n  Gres=gpu:V100:2 \\\n  State=UNKNOWN\n```\n\n### 4. 启用 GPU 隔离\n确认 `/etc/slurm/cgroup.conf` 包含：\n```conf\nConstrainDevices=yes\n```\n**重要**：未启用隔离会导致所有作业都能访问全部 GPU\n\n### 5. 重启服务\n```bash\nsystemctl restart slurmctld slurmd\n```\n\n## 十三、GPU 功能验证\n\n### 1. 查看节点资源\n```bash\nscontrol show node node1\n```\n应包含：\n```\nGres=gpu:V100:2\nGresUsed=0\n```\n\n### 2. 查看 GPU 视图\n```bash\nsinfo -o \"%N %G\"\n```\n输出示例：\n```\nnode1 gpu:V100:2\n```\n\n## 十四、GPU 作业示例\n\n### 1. 交互式任务（单 GPU）\n```bash\nsrun --gres=gpu:V100:1 --pty bash\nnvidia-smi  # 应只看到1张GPU\n```\n\n### 2. 批处理任务\n```bash\ncat > gpu_test.sh <<'EOF'\n#!/bin/bash\n#SBATCH -J gpu_test\n#SBATCH --gres=gpu:V100:1\n#SBATCH --cpus-per-task=4\n#SBATCH --mem=16G\n#SBATCH -o gpu_test.out\n\nnvidia-smi\nsleep 30\nEOF\n\nsbatch gpu_test.sh\n```\n\n### 3. 多 GPU 任务\n```bash\nsrun --gres=gpu:V100:2 --pty bash\n```\n\n## 十五、常见 GPU 问题\n\n### ❌ 作业内能看到所有 GPU\n**原因**：\n- `ConstrainDevices=no`\n- 未使用 `task/cgroup`\n\n**修复**：\n```conf\nConstrainDevices=yes\nTaskPlugin=task/cgroup\n```\n\n### ❌ 提交 GPU 作业一直排队\n```bash\nsqueue\nscontrol show job <jobid>\n```\n**常见原因**：\n- GPU 已被占用\n- 请求的 GPU 类型错误（如写成 A100）\n\n### ❌ GPU 规格指定差异\n| 写法                | 行为         |\n|---------------------|--------------|\n| `--gres=gpu:1`      | 使用任意 GPU |\n| `--gres=gpu:V100:1` | 仅使用 V100  |\n\n生产环境建议始终指定 GPU 类型\n\n## 十六、生产环境建议\n\n### 1. 资源限制\n在分区配置中添加：\n```conf\nDefMemPerGPU=32000  # 每GPU分配32GB内存\n```\n避免 GPU 作业抢占全部内存\n\n### 2. 节点隔离\n未来扩展多节点时，使用独立分区区分 GPU/CPU 节点\n\n## 总结\nV100 GPU 的配置需要同时满足：\n1. 正确的 `gres.conf` 定义\n2. `slurm.conf` 中的资源声明\n3. `cgroup.conf` 的设备隔离\n\n根据需求可进一步配置：\n- MIG / 多 GPU 混合调度\n- GPU + CPU 绑核（NUMA 亲和）\n- GPU 分区 / QOS\n- 多用户 GPU 计费","tags":["Slurm","HPC","集群管理"]},{"title":"广义动量守恒推导","url":"/2025/02/27/rel_mom/","content":"\n下面给出一个较为详细的推导思路，说明为什么会得到方程\n$$\n\\frac{d}{dt}\\left(\\mathbf{p}_\\perp + q\\,\\mathbf{A}\\right) = 0 \\quad \\Longrightarrow \\quad \\mathbf{p}_\\perp = \\mathbf{p}_\\perp^0 - q\\,\\mathbf{A},\n$$\n以及 $\\mathbf{p}_\\perp^0 = m \\gamma^0 \\mathbf{v}_\\perp^0$ 等结果。这里 $\\mathbf{p}_\\perp$ 指的是粒子的横向(与主传播方向正交)动量，$\\mathbf{A}$ 是电磁势(矢势)，$q$ 是粒子电荷，$m$ 是粒子质量，$\\gamma$ 是相对论因子。下面分步骤说明。\n\n---\n\n## 1. 广义动量的定义与运动方程\n\n在经典电动力学中，带电粒子在电磁场中运动的拉格朗日量可以写作  \n$$\n\\mathcal{L} \\;=\\; -\\,m c^2\\,\\sqrt{1 - v^2/c^2} \\;+\\; q\\,\\mathbf{A}\\cdot\\mathbf{v} \\;-\\; q\\,\\phi,\n$$  \n其中 $\\mathbf{A}$ 是矢势、$\\phi$ 是标势，$\\mathbf{v}$ 是粒子速度，$c$ 是光速。相应的**广义动量**(canonical momentum)定义为  \n$$\n\\mathbf{P} \\;=\\; \\frac{\\partial \\mathcal{L}}{\\partial \\mathbf{v}} \n\\;=\\; \\mathbf{p} + q\\,\\mathbf{A},\n$$  \n其中  \n$$\n\\mathbf{p} \\;=\\; \\gamma m\\,\\mathbf{v} \n\\quad (\\text{惯性动量或机械动量}).\n$$  \n因此  \n$$\n\\mathbf{p} \\;=\\; \\mathbf{P} \\;-\\; q\\,\\mathbf{A}.\n$$\n\n### 电磁场中的牛顿方程\n带电粒子在电磁场中的相对论运动方程(牛顿-洛伦兹方程)可以写作  \n$$\n\\frac{d\\mathbf{p}}{dt} \\;=\\; q\\,\\bigl(\\mathbf{E} + \\mathbf{v}\\times\\mathbf{B}\\bigr).\n$$  \n若用广义动量 $\\mathbf{P} = \\mathbf{p} + q\\mathbf{A}$ 来表述，则有  \n$$\n\\frac{d\\mathbf{P}}{dt} \n\\;=\\; q\\,\\mathbf{E} + q\\,\\frac{d\\mathbf{A}}{dt} \n\\;=\\; q\\bigl(\\mathbf{E} + \\mathbf{v}\\times\\mathbf{B}\\bigr),\n$$  \n因为 $\\mathbf{E} = -\\,\\nabla \\phi - \\partial_t \\mathbf{A}$ 且 $\\mathbf{v}\\times\\mathbf{B}$ 也可以用 $\\mathbf{A}$ 表示。经过一系列推导后，若在某些方向(比如横向方向 $\\perp$)上，系统的对称性或平移不变性保证了对该分量的广义动量守恒，那么就会得到  \n$$\n\\frac{d}{dt}(\\mathbf{p}_\\perp + q\\,\\mathbf{A}_\\perp) \\;=\\; 0.\n$$\n\n---\n\n## 2. 为何 $\\frac{d}{dt}(\\mathbf{p}_\\perp + q\\,\\mathbf{A}) = 0$？\n\n在文中(方程(10b))，作者给出的理由是「由于在 $y$ 和 $z$ 方向的平移不变性(translational invariance)」，导致横向广义动量不随时间变化，即  \n$$\n\\frac{d}{dt}\\bigl(\\mathbf{p}_\\perp + q\\,\\mathbf{A}\\bigr) = 0.\n$$  \n换言之，在横向方向(相对于主传播或流动方向)没有空间上的变化或外力的额外依赖，因而该分量的广义动量守恒。  \n\n如果令 $\\mathbf{p}_\\perp^0$ 表示 $t < 0$ 时刻(或“初始”)的横向动量，且当 $t<0$ 时矢势 $\\mathbf{A} = 0$，那么守恒量就是  \n$$\n\\mathbf{p}_\\perp^0 + q\\,\\mathbf{A}\\big|_{t<0} \\;=\\; \\mathbf{p}_\\perp^0.\n$$  \n因为守恒，所以在 $t\\ge 0$ 的任何时刻都满足  \n$$\n\\mathbf{p}_\\perp(t) + q\\,\\mathbf{A}(t) \\;=\\; \\mathbf{p}_\\perp^0.\n$$  \n从而得到  \n$$\n\\mathbf{p}_\\perp(t) \n\\;=\\; \\mathbf{p}_\\perp^0 - q\\,\\mathbf{A}(t).\n$$  \n这正是方程(11)的主要形式。\n\n---\n\n## 3. 初始横向动量 $\\mathbf{p}_\\perp^0$ 的物理含义\n\n<!-- 作者接下来又写道   -->\n$$\n\\mathbf{p}_\\perp^0 \\;=\\; m\\,\\gamma^0 \\,\\mathbf{v}_\\perp^0 \n\\;=\\; -\\,\\hat{\\mathbf{y}}\\,m\\,c\\,\\tan\\alpha,\n$$  \n表明最初(比如等离子体还未受到后续场作用时，$t<0$)，带电粒子在横向($\\perp$)方向有一个初始速度 $\\mathbf{v}_\\perp^0$，对应的相对论动量即  \n$$\n\\mathbf{p}_\\perp^0 = \\gamma^0 m \\mathbf{v}_\\perp^0.\n$$  \n这里 $\\gamma^0 = 1/\\sqrt{1 - (v_\\perp^0)^2/c^2}$ 表示初始速度对应的相对论因子。文中举例给出了 $\\mathbf{p}_\\perp^0 = -\\,\\hat{\\mathbf{y}}\\,m\\,c\\,\\tan\\alpha$ 这样一个具体数值，说明粒子初始时在负 $y$ 方向以一定速度($\\tan\\alpha$ 相关)运动。\n\n---\n\n## 4. 总结推导脉络\n\n1. **广义动量守恒的关键**：由于在横向方向上(这里指 $y,z$ 或者作者只关注某个正交方向)不存在对粒子的净推力，或者说系统在该方向上具备平移对称性，因此$\\mathbf{p}_\\perp + q\\,\\mathbf{A}$ 守恒。  \n2. **初始条件**：$t<0$ 时，$\\mathbf{A}=0$，故初始时刻的广义动量就是粒子的机械动量 $\\mathbf{p}_\\perp^0$。  \n3. **随时间推演**：由于守恒量不变，可写出  \n   $$\n   \\mathbf{p}_\\perp(t) + q\\,\\mathbf{A}(t) \n   \\;=\\; \\mathbf{p}_\\perp^0 \n   \\quad\\Longrightarrow\\quad\n   \\mathbf{p}_\\perp(t) \n   \\;=\\; \\mathbf{p}_\\perp^0 - q\\,\\mathbf{A}(t).\n   $$  \n4. **相对论动量表达**：$\\mathbf{p}_\\perp^0 = m\\,\\gamma^0\\,\\mathbf{v}_\\perp^0$，并且在具体物理情景(例如等离子体流动)中可以给出速度或动量的方向和大小，如文中的 $-\\hat{\\mathbf{y}}\\,m\\,c\\,\\tan\\alpha$。\n\n<!-- 这就是文中方程(10b) 和(11)背后的主要推导逻辑。 -->\n要点在于：  \n- 电磁场中，**机械动量** $\\mathbf{p}$ 并非一定守恒，但**广义动量** $\\mathbf{p} + q\\mathbf{A}$ 可能由于对称性而守恒。  \n- 一旦认定在某个方向上无净力(或场结构具备平移不变性)，就可断言那一方向的广义动量守恒，从而得到 $\\mathbf{p}_\\perp = \\mathbf{p}_\\perp^0 - q\\mathbf{A}$ 这样的形式。  \n- 初始条件决定了 $\\mathbf{p}_\\perp^0$ 的具体值，再结合守恒方程就能得到随时间演化的横向动量。"},{"title":"Cloudflare tunnel 内网穿透","url":"/2025/02/02/cloudflare/","content":"\n- https://cloudflared.cn/get-started/create-local-tunnel/\n\nCloudflare 实现内网穿透主要通过其 **Cloudflare Tunnel**（也叫 Argo Tunnel）功能来实现。它允许你在不暴露公共 IP 的情况下，将本地服务器或应用暴露到互联网上，从而实现内网穿透。以下是 Cloudflare Tunnel 的基本工作原理和步骤：\n\n### 工作原理：\n1. **Cloudflare Tunnel** 创建了一个从本地服务器到 Cloudflare 的加密隧道。你的应用或服务运行在内网中，但它通过这个隧道连接到 Cloudflare 的网络。\n2. **Cloudflare 网络** 接收到来自用户请求的流量，然后转发到本地服务器。\n3. 用户与本地服务进行交互时，数据流经过加密隧道传输，从而避免了暴露内网 IP 地址和端口。\n\n### 实现步骤：\n1. **注册 Cloudflare 账户并添加域名：**\n   - 如果还没有 Cloudflare 账户，首先去 [Cloudflare 官网](https://www.cloudflare.com) 注册一个。\n   - 将你的域名添加到 Cloudflare，并修改 DNS 设置（如果是现有域名）。\n\n2. **安装 Cloudflare Tunnel 客户端：**\n   - 在你的本地服务器上安装 `cloudflared` 客户端。你可以通过 [Cloudflare 的官方文档](https://developers.cloudflare.com/cloudflare-one/connections/connect-apps/install-and-setup/installation) 了解详细的安装过程。大致步骤：\n     - 在 Linux 上，你可以使用以下命令：\n       ```bash\n       wget https://github.com/cloudflare/cloudflared/releases/latest/download/cloudflared-linux-amd64.deb\n       sudo dpkg -i cloudflared-linux-amd64.deb\n       ```\n       对于没有sudo权限的普通用户\n       ```bash\n       wget https://github.com/cloudflare/cloudflared/releases/latest/download/cloudflared-linux-amd64\n       ```\n     - 也可以在 macOS、Windows 等其他平台上进行类似安装。\n     \n\n3. **认证 Cloudflare Tunnel：**\n   - 在服务器上运行以下命令，进行认证：\n     ```bash\n     cloudflared tunnel login\n     ```\n   - 该命令会打开一个浏览器窗口，要求你登录到 Cloudflare 账户并授权。\n\n4. **创建 Tunnel：**\n   - 创建一个新的 Tunnel：\n     ```bash\n     cloudflared tunnel create <tunnel-name>\n     ```\n   - 这会生成一个隧道 ID 和证书文件。\n\n5. **配置 Tunnel 代理：**\n   - 设置隧道代理，通常是在本地应用监听的端口上。例如，如果你的服务在 `localhost:8080` 上运行，可以使用以下命令将流量通过隧道转发：\n     ```bash\n     cloudflared tunnel --url http://localhost:8080\n     ```\n   - 或者也可以直接更改配置文件\"~/.cloudflared/config.yml\"\n    ```\n    tunnel: 6bc4c976-1c0c-45a4-bab0-93b7eed4e1d1 # 你的 Tunnel ID\n    credentials-file: $HOME/.cloudflared/6bc4c976-1c0c-45a4-bab0-93b7eed4e1d1.json\n\n    ingress:\n    - hostname: rentereview.cn\n        service: http://localhost:8080  # 你的 Web 服务监听端口\n    - service: http_status:404\n    ```\n   - 然后运行\n    ```bash\n    cloudflared tunnel run <tunnel-name>\n    ```\n6. **配置 DNS 和路由：**\n   - 在 Cloudflare 控制面板中，配置你的 DNS 设置，将域名指向 `cloudflare-tunnel`。\n   - 在 Cloudflare 的 DNS 配置中，添加一条 CNAME 记录，将子域（例如 `tunnel.yourdomain.com`）指向 `tunnel.cloudflare.com`。\n   - 总结一下\n   - 在 Cloudflare 控制面板中，通过 DNS 设置，手动添加一个 CNAME 记录，将子域（如 tunnel.retereview.cn）指向 your-tunnel-id.cfargotunnel.com。\n   - 确保你的 Cloudflare Tunnel 在本地启动并运行。\n   - 等待 DNS 记录生效后，你应该就可以通过访问 tunnel.retereview.cn 来访问你本地的服务了。\n\n   - 或者通过cloudflared程序进行路由\n   ```bash\n   cloudflared tunnel route dns <tunnel-name> rentereview.cn\n   ```\n   - 这将把域名 rentereview.cn 路由到名为 <tunnel-name> 的 Tunnel。\n7. **启动和验证：**\n    - 运行 Cloudflare Tunnel 服务：\n      ```bash\n      cloudflared tunnel run <tunnel-name>\n      ```\n    - 此时，你的本地服务就已经通过 Cloudflare Tunnel 暴露到互联网上了。\n\n8. **持久化服务（使用 systemd）**\n    - 以上步骤中运行 `cloudflared tunnel run` 的方式在终端退出后就会停止，为了让服务在后台持续运行，可以使用 systemd 来管理。\n\n    **方法一：使用 systemd 创建服务（推荐）**\n\n    1. 创建服务文件\n       使用文本编辑器创建服务文件：\n       ```bash\n       sudo nano /etc/systemd/system/cloudflared-tunnel.service\n       ```\n\n    2. 服务文件内容\n       将以下内容复制到文件中，注意替换 `<tunnel-name>` 为你的隧道名称：\n       ```\n       [Unit]\n       Description=Cloudflare Tunnel\n       After=network.target\n\n       [Service]\n       Type=simple\n       User=root\n       ExecStart=/usr/local/bin/cloudflared tunnel run <tunnel-name>\n       Restart=always\n       RestartSec=5\n       # 可选：设置环境变量\n       Environment=TUNNEL_ORIGIN_CERT=/path/to/cert.pem\n       # 可选：指定配置文件\n       Environment=CLOUDFLARED_CONFIG=/path/to/config.yml\n\n       [Install]\n       WantedBy=multi-user.target\n       ```\n\n    3. 启用并启动服务\n       依次执行以下命令：\n       ```bash\n       # 重新加载 systemd\n       sudo systemctl daemon-reload\n\n       # 启用开机自启\n       sudo systemctl enable cloudflared-tunnel.service\n\n       # 启动服务\n       sudo systemctl start cloudflared-tunnel.service\n       ```\n\n       之后，可以使用以下命令检查服务状态和日志：\n       ```bash\n       # 检查状态\n       sudo systemctl status cloudflared-tunnel.service\n\n       # 查看日志\n       sudo journalctl -u cloudflared-tunnel.service -f\n       ```\n\n9. **启用 \"Always Use HTTPS\" 设置**\n    - Cloudflare 提供了一个非常简单的方法来自动将所有 HTTP 流量重定向到 HTTPS：通过 \"Always Use HTTPS\" 选项。这是最直接的方式，适用于大多数场景。\n\n    - 操作步骤：\n    - 登录到你的 Cloudflare 控制面板。\n    - 选择你要配置的域名。\n    - 进入 \"SSL/TLS\" 设置页面。\n    - 在页面顶部，点击 \"Edge Certificates\" 选项卡。\n    - 向下滚动，找到 \"Always Use HTTPS\" 设置。\n    - 开启这个选项，将所有的 HTTP 请求自动重定向到 HTTPS。\n\n### 优点：\n- **安全性高**：内网不需要暴露在公网，只通过加密隧道进行通信。\n- **无公网 IP**：适用于没有固定公网 IP 的环境。\n- **简化配置**：不需要复杂的端口映射或 NAT 配置。\n\n### 注意：\n- Cloudflare Tunnel 是一种基于 Cloudflare 的服务，因此需要有一个 Cloudflare 账户，并且 DNS 需要指向 Cloudflare 才能使用。\n- 可能会有流量限制或费用问题，特别是在高流量场景下。\n\n这种方式的好处是可以轻松实现内网穿透，并且利用 Cloudflare 的全球加速和安全防护功能，使你的应用更加可靠和安全。如果有其他问题，或对某些配置有疑问，欢迎继续提问！\n"},{"title":"Subtree仓库添加","url":"/2025/02/02/subtree/","content":"\n## Step 1\n初始化 git 仓库并提交初始文件\n\n```bash\n# 在当前目录初始化仓库\ngit init\n\n# 创建或编辑 README.md（示例）\necho \"# 项目\" > README.md\n\n# 将所有改动添加到暂存区\ngit add .\n\n# 提交到本地仓库\ngit commit -m \"Init\"\n```\n\n解释：\n- git init：在当前目录创建一个新的 Git 仓库（.git 目录）。\n- git add .：把当前目录下的所有新文件和修改记录到暂存区，准备提交。\n- git commit -m \"Init\"：把暂存区内容作为一次提交写入本地仓库，-m 后面是提交说明。\n\n## Step 2\n把另一个仓库作为子树（subtree）添加到本仓库的某个目录\n\n```bash\n# 添加远程仓库（label 为远程名，<git-url> 为远程仓库地址）\ngit remote add label <git-url>\n\n# 抓取远程分支到本地（不合并，只获取引用和对象）\ngit fetch label\n\n# 将远程仓库的某个分支以子树形式合并到当前仓库的指定目录\ngit subtree add --prefix=<path> label <branch>\n# 可选：加上 --squash 将远程历史合并为单个提交\n# git subtree add --prefix=<path> label <branch> --squash\n```\n\n解释：\n- git remote add label <git-url>：为远程仓库起一个名字（这里用 label），便于后续引用。\n- git fetch label：从名为 label 的远程抓取最新对象和引用，但不自动合并到当前分支。\n- git subtree add --prefix=<path> label <branch>：\n    - --prefix=<path>：把子仓库的内容导入到当前仓库的 <path> 目录下（该目录会被创建）。\n    - label：上一步添加的远程名。\n    - <branch>：远程仓库中要导入的分支名（如 master 或 main）。\n    - 该命令会把远程分支的内容合并到本仓库的指定目录，并保留可追溯的合并提交；--squash 可把全部历史压缩为一个提交。\n\n补充常用操作：\n- 更新子树到远程最新：git subtree pull --prefix=<path> label <branch> [--squash]\n- 将子树的变更推送回远程：git subtree push --prefix=<path> label <branch>\n\n注意事项：\n- git subtree 在现代 Git 中通常可用；若不可用，需安装 contrib 工具或使用其他方式（如 git submodule）。\n- 在使用前确认 <path>、<git-url>、<branch> 填写正确，避免覆盖已有重要文件。\n- 若希望保留完整历史，勿使用 --squash；若想保持主仓库历史简洁，可使用 --squash。\n- 相关操作会在本地产生合并提交，合并策略与普通合并类似，请根据需要在分支上操作并做好备份。\n"},{"title":"机器学习资源","url":"/2023/08/10/datascience/","content":"\n## 数据分析入门\n\nhttps://github.com/apachecn/pyda-2e-zh.git\n\n## Twitter算法\n\nhttps://github.com/twitter/the-algorithm.git\n\n## Data Science笔记\n\nhttps://github.com/fengdu78/Data-Science-Notes\n\n## Machine Learning笔记\n\n吴恩达Machine learning笔记。\n\nhttps://github.com/fengdu78/Coursera-ML-AndrewNg-Notes.git\n\n## 100-Day-Machine-Learning\n\n100-Days-Of-ML-Code中文版\n\nhttps://github.com/MLEveryday/100-Days-Of-ML-Code.git\n\n## Deep Learning Book\n\nDeep Learning Book Chinese online： https://exacity.github.io/deeplearningbook-chinese/Chapter1_introduction/\n\nSource Code： https://github.com/exacity/deeplearningbook-chinese.git\n\n## Huawei 拍月亮\n\nhttps://github.com/zhazhajust/Learning-to-See-in-the-Dark.git\n\n## GPT2.0\n\n基于开源GPT2.0的初代创作型人工智能 | 可扩展、可进化\n\nhttps://github.com/EssayKillerBrain/WriteGPT.git\n\n## Full Stack\n\n🚀 fullstack tutorial 2022，后台技术栈/架构师之路/全栈开发社区，春招/秋招/校招/面试。\n\nhttps://github.com/frank-lam/fullstack-tutorial.git\n\n## Java\n\n21天学会JAVA\n\nhttps://github.com/DuGuQiuBai/Java.git"},{"title":"远程连接与唤醒","url":"/2023/08/10/remote/","content":"\n## 简介\n\n首先准备好公网ipv4 or ipv6，使用ddns-go绑定动态ip地址到dns服务器（静态ip不需要），此时可。随后运行WolGoWeb服务，即可使用url进行远程唤醒。\n\n## dynv6\n\n使用 https://dynv6.com 进行动态域名解析，绑定ipv6于自定义域名 https://xxx.dynv6.net 。\n\n## ddns-go\n\n简单好用的DDNS。自动更新域名解析到公网IP(支持阿里云、腾讯云、Dnspod、Cloudflare、Callback、华为云、百度云、Porkbun、GoDaddy、Google Domain)\n\nhttps://github.com/jeessy2/ddns-go.git\n\n此时，ipv6已解析于ddns服务器，通过自定义url可以通过远程连接软件如rdp、moonlight、parsec等直接访问。\n\n## WolGoWeb\n\n基于Golang的Web服务器，使用url链接即可发起wake on lan局域网唤醒。\n\nhttps://github.com/zhazhajust/WolGoWeb.git\n\n然后测试url唤醒，在浏览器输入 http://xxx:9090/wol?mac=00-00-00-00-00-00 （网卡MAC地址）。\n\n## Wake On Lan GUI 程序（Optional）\nhttps://github.com/basildane/WakeOnLAN.git\n\n### 参考文献\n\nhttps://www.jianshu.com/p/6622c33f4cd3\n\nhttps://zhouym.tech/2022/Wake-On-Lan/\n"},{"title":"Frequency moved undulator","url":"/2022/09/15/undulator/","content":"\n## Smilei or EPOCH\n\nMark the oscillate electrons, and save the field produced by them. Then sparated them from the total electric field and save to a new file.\n\n## 光波荡器推导\n\n假设平面波激光方向为$\\hat k = \\frac{\\mathbf{k}}{k_L}$，则 $B = \\frac{(\\hat k \\times E)}{c}$，电子在激光场中运动方程写为：\n\n$$\n\\frac{d}{dt}(\\gamma mc \\beta) = -e(E + v \\times B)\n$$\n\n$$\n\\frac{d}{dt}(\\gamma mc \\beta) = -e[E + \\beta \\times (\\hat k \\times E)] = -e[E + (\\beta \\cdot E)\\hat k - (\\beta \\cdot \\hat k)E]\n$$\n\n我们假设激光沿着x方向偏振，$E = E_0 \\sin(\\omega_Lt − k \\cdot x)\\hat x$，沿着z方向传播，与z轴呈夹角$\\varphi$，波矢$k = k_L(0, -\\sin \\varphi, +\\cos \\varphi)$，并且 $\\omega_L = ck_L$。运动方程写为：\n\n$$\n\\frac{d}{dt}(\\gamma mc \\beta) = -eE_0\\sin(ck_Lt - \\mathbf{k} \\cdot x)[1 - (\\hat k \\cdot \\beta)] = \\frac{eE_0}{ck_L}\\frac{d}{dt}\\cos(ck_Lt - \\mathbf{k} \\cdot x)\n$$\n\n方程表明水平方向动量守恒，通过积分可以很容易得出，\n\n$$\n\\beta_x = \\frac{eE_0}{\\gamma mc^2k_L}\\cos(ck_Lt - \\mathbf{k}\\cdot x)\n$$\n\n波荡器参数为$K = \\frac{eE_0}{mc^2k_L}$，对于Undulator， $K<<1$，$t \\approx c/\\beta_z$，横向振动速度为$\\cos(k_L(1/\\overline{\\beta}_z - \\cos\\varphi)z + k_Ly\\sin\\varphi)$，则波荡器周期为：\n\n$$\n\\lambda_u \\rightarrow \\frac{\\overline{\\beta}_z\\lambda_L}{1 - \\overline{\\beta}_z\\cos\\varphi}\n$$\n\n将波荡器周期和参数K带入波荡器辐射公式,\n\n$$\n\\frac{\\lambda_1(\\phi)}{c} = \\frac{\\lambda_u}{c}[\\frac{1 + K^2/(4\\gamma^2)}{\\beta} - (1 - \\frac{\\phi^2}{2})] \\approx \\frac{\\lambda_u}{c}\\frac{1 + K^2/2 + \\gamma^2\\phi^2}{2\\gamma^2}\n$$\n\n同步辐射共振波长为\n\n$$\n\\lambda = \\frac{1 + K^2/2}{2\\gamma^2}\\frac{\\lambda_L}{1 - \\overline{\\beta}_z\\cos\\varphi}\n$$\n\n当满足$\\varphi \\rightarrow 0, K << 1$(undulator的假设)时\n\n$$\n\\lambda \\rightarrow \\lambda_L\n$$\n\n## 时间收缩效应\n\n假设$t^{'}$为粒子静止坐标系，则 $1 - \\beta(t^{'})\\cos\\phi(t^{'})$ 为时间收缩因子，对于相对论电子，\n\n$$\n\\beta = \\sqrt{1 - \\frac{1}{\\gamma^2}} \\approx 1 - \\frac{1}{1\\gamma^2}\n$$\n\n对于$\\gamma >> 1$，$\\phi << 1$\n\n$$\n1 - \\beta \\cos\\phi \\approx \\frac{1}{2}(\\frac{1}{\\gamma^2} + \\phi^2)\n$$"},{"title":"偏微分方程求解","url":"/2022/08/17/numerical/","content":"\n# 偏微分方程求解\n\n对于波动方程等偏微分方程，难以直接求解析解，一般采用数值方法求解。目前电磁学主要通过有限元法（FEM）（通过Galerkin法基函数分解）、有限时域差分法（FDTD）、矩量法（MoM）等进行数值模拟。对于更一般的偏微分方程求解方法，这里介绍Method of Lines方法求解。\n\n## Method of Lines\n\nMethod of Lines是求解偏微分方程的一种通用计算方法。Method of Lines方法通过空间离散，将偏微分方程转化为常微分方程组ODEs，后续通过Eular法，隐式欧拉法（牛顿迭代、不动点法）等求解。\n\n## 基本案例\n\n例：求解扩散方程\n\n$$\n\\frac{\\partial u}{\\partial t} = D\\frac{\\partial^2 u}{\\partial x^2}\n$$\n\n将$D\\frac{\\partial^2}{\\partial x^2}$离散化为矩阵$A$，将$\\frac{d}{dt}U$写为$\\dot U$，使用矩阵形式表示为$\\dot U = AU$。\n\n\n例如$\\frac{du_i}{dt} = -v\\frac{du}{dx}$\n方程转化为$\\frac{du_i}{dt} = -v\\frac{(u_i - u_{i-1})}{\\delta x}, 1 \\leq i \\leq M$，再转化为矩阵形式。\n\n## forward eular\n\n讲矩阵乘积写为函数形式\n$$\n\\dot U = F(U)\n$$\n则可使用前向欧拉法进行求解\n$$\nU_{k+1} = U_k + \\delta tF(U_k)\n$$\n\n## RK方法\n\n龙格库塔方法显式求解Method of Lines得到的ODEs，可以得到更高精度的解。\n\n积分中值定理可以得出\n$$\nU(t + \\delta t) = U(t) + \\delta tF(U(t + \\frac{1}{2}\\delta t)) + O(\\delta t^3)\n$$\n\n龙格库塔法通过预测$U(t + \\frac{1}{2}\\delta t)$来使用前向欧拉法\n$$\n\\widetilde U_{k+\\frac{1}{2}} = U_k + \\frac{\\delta t}{2}F(U_k)\n$$\n\n$$\nU_{k+1} = U_k + \\delta tF(\\widetilde U_{k+\\frac{1}{2}})\n$$\n\n这是一种两阶段方法。第一阶段预测中点值，第二阶段，即校正阶段，使用预测的中点值进行时间步进。"},{"title":"牛顿迭代法隐式欧拉法求解微分方程","url":"/2022/08/16/NewtonMethod/","content":"\n# 牛顿迭代法求解ODE\n\n首先根据 \\(\\frac{dy}{dx} = f(x, y)\\) 构建 \\(F(x, y) = 0\\)，然后求解\\(F(x, y)\\)对\\(y\\)的导数，然后迭代求解零点误差 \\(\\text{abs}(F(x, y) - F(x, \\text{next}_y))\\) 最小处的\\(y\\)，将\\(\\text{next}_y\\)作为\\(y\\)带入下一个递归，\n\n```\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport sympy\n\nx = np.zeros(20)\ny = np.zeros(20)\ny_E = np.zeros(20)\nz = np.zeros(20)\nx[0] = 0\ny[0] = 1\ny_E[0] = 1\nz[0] = (1+2*x[0])**0.5\nh = 0.05\n\n# dy/dx 导数\ndef f(x, y):\n    return y-2*x/y\n\n############################\n##### 牛顿迭代法构建方程 #####\n############################\n\n# dy/dx = f(x, y)\n# y - yn = (x - xn) * f(x, y)\n# h * f(x, y) - (y - yn) = 0\ndef F(x, y, yn):\n    return h * f(x, y) - (y - yn)\n\n# 求解dF(x, y, yn)/dy\n# d(0.05 * (y - 2*x/y) - y + yn) / dy\n# 0.05 * (1 + 2*x/y**2) - 1\n# 0.1 * x/y**2 - 0.95\ndef dF(x, y):\n    return 0.1*x/y**2 - 0.95\n\n############################\n############################\n############################\n\ndef newtonMethod(assum, d1, d3):\n    y = assum\n    Next_y = 0\n    if F(d1, y, d3) == 0.0:\n        return  y\n    else:\n        Next_y = y - F(d1, y, d3) / dF(d1, y)\n\n    # 零点距离\n    if abs(F(d1, y, d3) - F(d1, Next_y, d3)) < 1e-5:\n        return Next_y\n        '''设置迭代跳出条件, 同时输出满足f(x) = 0的x值'''\n    else:\n        return newtonMethod(Next_y, d1, d3)\n\n\nfor i in range(1, 20):\n    x[i] = x[i-1]+h\n    y[i] = newtonMethod(4, x[i], y[i-1])\n    y_E[i] = y_E[i-1] + h*f(x[i-1], y_E[i-1])\n    z[i] = (1+2*x[i])**0.5\n\nplt.plot(x, y, label='Implicit Euler', color='green')\nplt.plot(x, y_E, label='Euler', color='orange')\nplt.plot(x, z, label='true', color='red')\nplt.legend()\nplt.show()\n```"},{"title":"Marching Cube算法提取网格","url":"/2022/08/15/pymesh/","content":"\n\n# PyMesh3D\n\n## Basic Installation\n\nThis project for mesh render in data science.\n\n```python\npip install --upgrade pip\npip install pymesh3d\n```\n\nIf you need mayavi backend.\n\n```python\npip install mayavi\npip install pyqt\n```\n\n## Quick Start\n\n```python\nimport pymesh\nimport numpy as np\nimport matplotlib.pyplot as plt\n```\n\nLook at the directory example for full example.\n\n```python\n##########################################\n############ Rotate Mesh Data ############\n##########################################\n\nwkdir = \"../../Render\"\n\ney = np.load(wkdir + \"/Ez.npy\")[::2, ::50]\n\nm, n = ey.shape[0], ey.shape[1]\nres = np.zeros([m, n, n])\npymesh.rotate(ey, res, ifhalf = False)\n\nfig = plt.figure(figsize=(4, 3))\nplt.contourf(res[:, int(n/2), :].T)\ncbar = plt.colorbar()\n```\n\n![png](https://github.com/zhazhajust/pymesh/blob/main/example/example_files/example_1_0.png?raw=true)\n\n```python\n##########################################\n############# Save Mesh Data #############\n##########################################\n\nmesh = pymesh.get_iso_surf(res, contours_number = 4, cmap = \"jet\")\ncolor = pymesh.interp_color(mesh.iso_vals, cmap = \"jet\")\nmesh.export(wkdir + \"test\", \"obj\")\n```\n\n```python\n##########################################\n############# Load Mesh Data #############\n##########################################\n\nmesh = pymesh.Mesh.load(wkdir + \"test\", \"obj\")\n```\n\n```python\n##########################################\n############# Plot Mesh Data #############\n##########################################\n```\n\n```python\nfrom mayavi import mlab\n\nmlab_mesh = pymesh.iso_surface(mesh, colormap = \"RdBu\")\nmlab.colorbar()\nmlab.show()\n```\n![png](https://github.com/zhazhajust/pymesh/blob/main/example/example_files/example_3_0.png?raw=true)\n\n```python\n################ plt example #################\n\nsurf = mesh.plt_trisurf(cmap = \"jet\")\nplt.colorbar(surf, orientation = 'horizontal')\nplt.tight_layout()\n```\n\n![png](https://github.com/zhazhajust/pymesh/blob/main/example/example_files/example_2_0.png?raw=true)\n"},{"title":"动态开点线段树","url":"/2022/07/09/segmentTree/","content":"\n## 动态线段树模板\n\n```C++\n\n/**\n * @Description: 线段树（动态开点）\n * @Author: LFool\n * @Date 2022/6/7 09:15\n **/\npublic class SegmentTreeDynamic {\n    class Node {\n        Node left, right;\n        int val, add;\n    }\n    private int N = (int) 1e9;\n    private Node root = new Node();\n    public void update(Node node, int start, int end, int l, int r, int val) {\n        if (l <= start && end <= r) {\n            node.val += (end - start + 1) * val;\n            node.add += val;\n            return ;\n        }\n        int mid = (start + end) >> 1;\n        pushDown(node, mid - start + 1, end - mid);\n        if (l <= mid) update(node.left, start, mid, l, r, val);\n        if (r > mid) update(node.right, mid + 1, end, l, r, val);\n        pushUp(node);\n    }\n    public int query(Node node, int start, int end, int l, int r) {\n        if (l <= start && end <= r) return node.val;\n        int mid = (start + end) >> 1, ans = 0;\n        pushDown(node, mid - start + 1, end - mid);\n        if (l <= mid) ans += query(node.left, start, mid, l, r);\n        if (r > mid) ans += query(node.right, mid + 1, end, l, r);\n        return ans;\n    }\n    private void pushUp(Node node) {\n        node.val = node.left.val + node.right.val;\n    }\n    private void pushDown(Node node, int leftNum, int rightNum) {\n        if (node.left == null) node.left = new Node();\n        if (node.right == null) node.right = new Node();\n        if (node.add == 0) return ;\n        node.left.val += node.add * leftNum;\n        node.right.val += node.add * rightNum;\n        // 对区间进行「加减」的更新操作，下推懒惰标记时需要累加起来，不能直接覆盖\n        node.left.add += node.add;\n        node.right.add += node.add;\n        node.add = 0;\n    }\n}\n\n```\n\n对于表示为「区间和」且对区间进行「加减」的更新操作的情况，我们在更新节点值的时候『需要✖️左右孩子区间叶子节点的数量 (注意是叶子节点的数量)』；我们在下推懒惰标记的时候『需要累加』！！(这种情况和模版一致！！) 如题目 最近的请求次数\n对于表示为「区间和」且对区间进行「覆盖」的更新操作的情况，我们在更新节点值的时候『需要✖️左右孩子区间叶子节点的数量 (注意是叶子节点的数量)』；我们在下推懒惰标记的时候『不需要累加』！！(因为是覆盖操作！！) 如题目 区域和检索 - 数组可修改\n对于表示为「区间最值」且对区间进行「加减」的更新操作的情况，我们在更新节点值的时候『不需要✖️左右孩子区间叶子节点的数量 (注意是叶子节点的数量)』；我们在下推懒惰标记的时候『需要累加』！！ 如题目 我的日程安排表 I、我的日程安排表 III\n\n## 我的日程安排表 I\n\n```C++\n\nclass Node {\n    friend class MyCalendar;\n    // 左右孩子节点\n    Node *left, *right;\n    // 当前节点值，以及懒惰标记的值\n    int val, add;\n};\n\nclass MyCalendar {\n    public:    \n        MyCalendar():N(1e9), root(new Node()){\n        }\n        bool book(int start, int end) {\n            // 先查询该区间是否为 0\n            if (query(root, 0, N, start, end - 1) != 0) return false;\n            // 更新该区间\n            update(root, 0, N, start, end - 1, 1);\n            return true;\n        }\n        void update(Node* node, int start, int end, int l, int r, int val) {\n            if (l <= start && end <= r) {\n                node -> val += val;\n                node -> add += val;\n                return ;\n            }\n            pushDown(node);\n            int mid = (start + end) >> 1;\n            if (l <= mid) update(node -> left, start, mid, l, r, val);\n            if (r > mid) update(node -> right, mid + 1, end, l, r, val);\n            pushUp(node);\n        }\n        int query(Node* node, int start, int end, int l, int r) {\n            if (l <= start && end <= r) return node -> val;\n            pushDown(node);\n            int mid = (start + end) >> 1, ans = 0;\n            if (l <= mid) ans = query(node -> left, start, mid, l, r);\n            if (r > mid) ans = max(ans, query(node -> right, mid + 1, end, l, r));\n            return ans;\n        }\n    // *************** 下面是模版 ***************\n    private:\n        int N;\n        Node* root;\n        void pushUp(Node* node) {\n            // 每个节点存的是当前区间的最大值\n            node -> val = max(node -> left -> val, node -> right -> val);\n        }\n        void pushDown(Node* node) {\n            if (node -> left == nullptr) node -> left = new Node();\n            if (node -> right == nullptr) node -> right = new Node();\n            if (node -> add == 0) return ;\n            node -> left -> val += node -> add;\n            node -> right -> val += node -> add;\n            node -> left -> add += node -> add;\n            node -> right ->add += node -> add;\n            node -> add = 0;\n        }\n};\n\n/**\n * Your MyCalendar object will be instantiated and called as such:\n * MyCalendar* obj = new MyCalendar();\n * bool param_1 = obj->book(start,end);\n */\n\n```"},{"title":"滤波与反滤波","url":"/2022/07/03/conv/","content":"## 自相关\n\n```python\n\nfrom scipy import signal\nrng = np.random.default_rng()\nsig = rng.standard_normal(1000)\nautocorr = signal.fftconvolve(sig, sig[::-1], mode='full')\n\n```\n\n## 高斯滤波\n\n```python\nimport scipy\nfrom scipy.ndimage import gaussian_filter\nimport scipy.signal as signal\n\nc = 3e8\ndx = 1e-6 * (x[1] - x[0])\nsigma = c/10e12/dx\n\nEyTHz = scipy.ndimage.gaussian_filter(EyEnd, sigma = 15)\n\n```\n\n使用高斯核卷积进行滤波\n\n```python\n\nim = EyEnd\ngauss_kernel = np.outer(signal.gaussian(im.shape[0], 15), signal.gaussian(im.shape[1], 15))\n#gauss_kernel = gauss_kernel/np.sum(gauss_kernel)\ngauss_kernel /= np.trapz(np.trapz(gauss_kernel))\nim_real = signal.convolve(im, gauss_kernel, mode='same')\n#im_real = im * gauss_kernel\n\n```\n\n其中sigma为滤波宽度\n\n## 使用卷积实现滤波\n\n```python\n\nimport numpy as np\nfrom scipy import signal\n#from scipy import misc\nimport matplotlib.pyplot as plt\n\n####动态模糊核心\nguass_kernal = [[0, 0, 1],\n                [0, 1, 0],\n                [1, 0, 0]]\n\nresult = signal.convolve2d(origin, guass_kernal, boundary='symm', mode='same')\n\n```\n\n二维的卷积运算还有一种函数，是signal.sepfir2d()，它可以传入三个参数，后两个参数指定行和列的卷积和(两个方向上的卷积是可以不同的，分别指定卷积和序列)。\n\n## 频域卷积\n\n```python\n\nfrom scipy import signal\nimport numpy as np\nimport numpy.fft as fp\n\nim = EyEnd #EyEnd为需要滤波的图像\n\ngauss_kernel = np.outer(signal.gaussian(im.shape[0], 15), \nsignal.gaussian(im.shape[1], 15))\n\nplt.pcolormesh(gauss_kernel, cmap = 'jet')\n\nfreq = np.fft.fft2(im)\nassert(freq.shape == gauss_kernel.shape)\nfreq_kernel = np.fft.fft2(np.fft.ifftshift(gauss_kernel))\n\nfig = plt.figure(figsize = (10, 4))\nax_1 = fig.add_subplot(121, projection='3d')\nax_2 = fig.add_subplot(122, projection='3d')\n \nY = np.arange(0 - int(im.shape[0]/2), im.shape[0] - int(im.shape[0]/2), 1)\nX = np.arange(0 - int(im.shape[1]/2), im.shape[1] - int(im.shape[1]/2), 1)\nX, Y = np.meshgrid(X, Y)\n \nax_1.plot_surface(X, Y, np.log10(np.abs(fp.ifftshift(freq))), rstride=4,\ncstride=4, cmap=plt.cm.coolwarm)\n \nax_2.plot_surface(X, Y, np.abs(fp.ifftshift(freq_kernel)), rstride=4,\ncstride=4, cmap=plt.cm.coolwarm)\nplt.show()\n\nconv = freq*freq_kernel\nim1 = fp.ifft2(conv).real\n\n```\n\n简洁版\n\n```python\n\nfrom scipy import signal\nimport numpy as np\nimport numpy.fft as fp\n\ndef fftConv(im, sigma):\n\n    gauss_kernel = np.outer(signal.gaussian(im.shape[0], sigma), \n    signal.gaussian(im.shape[1], sigma))\n    plotFreq(freqX, freqY, gauss_kernel.T)\n\n    freq = np.fft.fft2(im)\n    assert(freq.shape == gauss_kernel.shape)\n    freq_kernel = np.fft.fft2(np.fft.ifftshift(gauss_kernel))\n    #freq_kernel = np.fft.fft2(gauss_kernel)\n    plotField(freqX, freqY, np.log10(np.abs(fp.ifftshift(freq))).T)\n    plotFreq(freqX, freqY, np.abs(fp.ifftshift(freq_kernel)).T) \n\n    conv = freq*freq_kernel\n    im1 = fp.ifft2(conv).real\n    return im1\n\nim = EyEnd\nplotField(x, y, im.T)\nsigma = 15\nim1 = fftConv(im, sigma)\nplotField(freqX, freqY, im1.T) \n\n```\n\n时域和频域对比\n\n```python\n\nimport matplotlib.pyplot as pylab\n\nfreq = np.fft.fft2(im)\nassert(freq.shape == gauss_kernel.shape)\nfreq_kernel = np.fft.fft2(np.fft.ifftshift(gauss_kernel))\nconv = freq * freq_kernel\nim1 = fp.ifft2(conv).real\n\npylab.figure(figsize = (20, 8))\npylab.gray()\npylab.subplot(2, 3, 1), pylab.pcolormesh(im.T, cmap = 'bwr'), pylab.title('Original Image', size = 30), pylab.axis('off')\npylab.subplot(2, 3, 2), pylab.pcolormesh(gauss_kernel.T, cmap = 'jet'), pylab.title('Gaussian Kernel', size = 30), pylab.axis('off')\npylab.subplot(2, 3, 3), pylab.pcolormesh(im1.T, cmap = 'bwr'), pylab.title('Output Image', size = 30), pylab.axis('off')\n\nimOrigin = (20*np.log10(np.abs(0.1+fp.ifftshift(freq)))).astype(int)\npylab.subplot(2, 3, 4), pylab.pcolormesh(imOrigin.T, cmap = 'bwr')\npylab.title('Origin Image Spectrum', size = 30), pylab.axis('off')\n\nimGuassian = (20*np.log10(np.abs(0.1+fp.ifftshift(freq_kernel)))).astype(int)\npylab.subplot(2, 3, 5), pylab.pcolormesh(imGuassian.T, cmap = 'jet')\npylab.title('Gaussian Kernel Spectrum', size = 30), pylab.axis('off')\n\nimOutSpec = (20*np.log10(np.abs(0.1+fp.ifftshift(conv)))).astype(int)\npylab.subplot(2, 3, 6), pylab.pcolormesh(imOutSpec.T, cmap = 'jet')\npylab.title('Output Image Spectrum', size = 30), pylab.axis('off')\n\n```\n\n## 带通滤波\n\n在这里尝试使用高斯差分核（两个高斯核的差），作为带通滤波器。带通滤波是保留一定频段内的频率分量，而丢弃其余所有的频率分量。\n\n```python\n###读取图像\nim = img_as_float(pylab.imread('./images/snow.jpg'))\npylab.figure(), pylab.imshow(im), pylab.axis('off'), pylab.show()\nx = np.linspace(-10, 10, 15)\n###kernel 1 生成\nkernel = np.exp(-0.005*x**2)\nkernel /= np.trapz(kernel)\nguass_kernel_1 = kernel[:, np.newaxis] * kernel[np.newaxis, :]\n###kernel 2 生成\nkernel = np.exp(-5*x**2)\nkernel /= np.trapz(kernel)\nguass_kernel_2 = kernel[:, np.newaxis] * kernel[np.newaxis, :]\n###进行差分\nDOGkernel = guass_kernel_1[:,:,np.newaxis] - guass_kernel_2[:,:,np.newaxis]\n###卷积\nim = signal.fftconvolve(im, DOGkernel, mode = 'same')\npylab.figure, pylab.imshow(np.clip(im, 0, 1)), pylab.axis('off'), print(np.max(im))\npylab.show()\n\n```\n\n## 使用傅里叶变换去卷积和逆滤波\n\n如果已经有了一张具有模糊核的模糊图像，我们需要将其恢复到原始图像。原理上，我们只需要对原有的滤波卷积核每一个值进行倒数的操作即可实现逆滤波器的效果。在此我们仍然是在频域上进行卷积，代码如下。\n\n需要注意的是，卷积核取到数的过程中需要在原来的数值上加一个微小数值epsilon，以避免分母为零。\n\n```python\n\nim = EyEnd #255*rgb2gray(imread('./images/snow.jpg'))\ngauss_kernel = np.outer(signal.gaussian(im.shape[0], 3), signal.gaussian(im.shape[1], 3))\n \nfreq = fp.fft2(im)\nfreq_kernel = fp.fft2(fp.ifftshift(gauss_kernel))\nconv = freq*freq_kernel\nim_blur = fp.ifft2(conv).real\nim_blur = 255*im_blur/np.max(im_blur)\n \nepsilon = 10**-6\nfreq = fp.fft2(im_blur)\nfreq_kernel = 1/(epsilon+freq_kernel) # avoid freq_kernel is zero\nim_rst = fp.ifft2(conv).real\nim_rst = 255*im_rst/np.max(im_rst)\n \npylab.figure(figsize = (10, 6))\npylab.subplot(221), pylab.imshow(im), pylab.title('Original Image'), pylab.axis('off')\npylab.subplot(222), pylab.imshow(im_blur), pylab.title('Blurred Image Image'), pylab.axis('off')\npylab.subplot(223), pylab.imshow(im_rst), pylab.title('Restored Image with inverse filter'), pylab.axis('off')\npylab.subplot(224), pylab.imshow(im_rst - im), pylab.title('Diff Image'), pylab.axis('off')\n\n```\n\n## 利用维纳滤波器去卷积\n\n前面的去卷积方法需要已知模糊核，在这里使用维纳滤波器，在不知道模糊核的情况下，从损坏的信号中去除噪声，达到复原图像的目的。首先构造一个已经损坏了的图像。\n\n```python\n\nim = rgb2gray(imread('./images/cat.jpg'))\n \nn = 7\npsf = np.ones((n, n))/n**2\nim1 = signal.convolve2d(im, psf, mode = 'same')\nim1 += 0.1*np.std(im1)*np.random.standard_normal(im.shape)\n\n```\n\n再使用维纳滤波完成操作，最后就能得到图像\n\n```python\n\nim2, _ = restoration.unsupervised_wiener(im1, psf)\nfig, axes = pylab.subplots(nrows = 1, ncols = 3, figsize = (200, 40), sharex = True,\n sharey = True)\npylab.gray()\naxes[0].imshow(im), axes[0].axis('off'), axes[0].set_title('Original image', size = 200)\naxes[1].imshow(im1), axes[1].axis('off'), axes[1].set_title('Noisy blurred image', size = 200)\naxes[2].imshow(im2), axes[2].axis('off'), axes[2].set_title('Self tuned restoration', size = 200)\nfig.tight_layout()\npylab.show()\n\n```\n\n## 使用低通滤波，重建图像\n\n```python\n\nim_fft = fp.ifftshift(im_fft_shift)\nim = np.clip(fp.ifft2(im_fft).real, 0, 255)\npylab.figure(figsize = (10,10))\npylab.imshow(im,pylab.cm.gray), pylab.axis('off'), pylab.title('Noise image'), pylab.show()\n\nkeep_fraction = 0.1\nr,c = im_fft.shape\nim_fft[int(r*keep_fraction):int(r*(1-keep_fraction))] = 0\nim_fft[:, int(c*keep_fraction):int(c*(1-keep_fraction))] = 0\npylab.figure(), plot_spectrum(fp.fftshift(im_fft)), pylab.title('Filitered Spectrum')\n\nim_new = fp.ifft2(im_fft).real\npylab.figure(figsize = (10, 10))\npylab.imshow(im_new,pylab.cm.gray), pylab.axis('off'), pylab.title('Reconstructed image'), pylab.show()\n\n```\n"},{"title":"分治算法","url":"/2022/07/01/Divide-and-Conquer/","content":"## 问题\n\n给你一个由数字和运算符组成的字符串 expression ，按不同优先级组合数字和运算符，计算并返回所有可能组合的结果。你可以 按任意顺序 返回答案。\n\n生成的测试用例满足其对应输出值符合 32 位整数范围，不同结果的数量不超过 \\(10^4\\) 。\n\n### 示例\n\n```C++\n输入：expression = \"2-1-1\"\n输出：[0,2]\n解释：\n((2-1)-1) = 0 \n(2-(1-1)) = 2\n```\n\n## 解题思路\n\n对于一个形如 x op y（op 为运算符，x 和 y 为数） 的算式而言，它的结果组合取决于 x 和 y 的结果组合数，而 x 和 y 又可以写成形如 x op y 的算式。\n\n因此，该问题的子问题就是 x op y 中的 x 和 y：以运算符分隔的左右两侧算式解。\n\n然后我们来进行 分治算法三步走：\n\n分解：按运算符分成左右两部分，分别求解\n解决：实现一个递归函数，输入算式，返回算式解\n合并：根据运算符合并左右两部分的解，得出最终解\n\n```C++\n\nclass Solution {\npublic:\n    vector<int> diffWaysToCompute(string expression) {\n        vector<int> vec1, vec2, res;\n        int flag = 0;\n        int n = expression.size();\n        for(int i = 0; i < n; i++){\n            char oper = expression[i];\n            if(oper == '+' || oper == '-' || oper == '*'){\n                flag = 1;\n                vec1 = diffWaysToCompute(string(expression, 0, i));\n                vec2 = diffWaysToCompute(string(expression, i + 1, n - i - 1));\n                for(auto v1: vec1){\n                    for(auto v2: vec2){\n                        if(oper == '+'){\n                            res.push_back(v1 + v2);\n                        }else if(oper == '-'){\n                            res.push_back(v1 - v2);\n                        }else{\n                            res.push_back(v1 * v2);\n                        }\n                    }\n                }\n            }\n        }\n        if(flag == 0){\n            return {std::stoi(expression)};\n        }\n        return res;\n    }\n};\n\n```\n\n以及**python**版本\n\n```python\n\nclass Solution:\n    def diffWaysToCompute(self, input: str) -> List[int]:\n        # 如果只有数字，直接返回\n        if input.isdigit():\n            return [int(input)]\n\n        res = []\n        for i, char in enumerate(input):\n            if char in ['+', '-', '*']:\n                # 1.分解：遇到运算符，计算左右两侧的结果集\n                # 2.解决：diffWaysToCompute 递归函数求出子问题的解\n                left = self.diffWaysToCompute(input[:i])\n                right = self.diffWaysToCompute(input[i+1:])\n                # 3.合并：根据运算符合并子问题的解\n                for l in left:\n                    for r in right:\n                        if char == '+':\n                            res.append(l + r)\n                        elif char == '-':\n                            res.append(l - r)\n                        else:\n                            res.append(l * r)\n\n        return res\n\n```\n"},{"title":"EPOCH Code For Spectrum","url":"/2022/06/30/centspec/","content":"\nUse EPOCH Code to get axis spectrum\n\n## SDF_Write\n\nUse this syntex can save axis Ey to file:\n\n```Fortran\nCALL sdf_write_plain_variable(sdf_handle, id, name, \nunits, dims, stagger, & grid_id, variable,\nsubtype_field, subarray_field)  \n```\n\nThe parameters have the following types and meanings:\n\n- **block id** - The id name of the variable. This character string is a unique identifier for the variable in the file enabling a program to retrieve it later. Once defined it should not change so that newer versions of EPOCH can still identify variables generated by older versions.\n\n- **name** - The display name of the variable. This character string is the name that is used by external programs to display an identifying name for the variable. If it contains '/' characters then these are used by VisIt to group the variables.\n\n- **units** - The units of the variable. This character string is used when displaying the data units. For most variables in EPOCH these are SI units.\n\n- **dims** - An nD integer array containing the GLOBAL length of the variable across all processors. In EPOCH a variable actually called \"dims\" exists for variables which are the same size as the default field variables.\n\n- **stagger** - An integer constant containing the stagger of a variable from the cell centre of a cell. This property lets external programs know the position of a variable on the grid.\n\n- **grid id** - The id name of the grid to which the variable is attached. In EPOCH , the main grid is just called \"grid\". Note that this property is case sensitive.\n\n- **variable** - The actual variable to be written to disk.\n\n- **subtype field** - This is an MPI type representing the layout of the data across the processors. For a standard field variable, there is an automatically created type called \"subtype field\" which should be used here.\n\n- **subarray field** - This is an MPI type representing the section of the \"variable\" parameter to be written. For a standard field variable, there is an automatically created type called \"subarray field\" which should be used here.\n\n## Example\n\nFor Example, derived variables **array**\n\n```Fortran\nIF (IAND(dumpmask(c_dump_myvar), code)) THEN\n  CALL calc_my_variable(array)\n  CALL sdf_write_plain_variable(sdf_handle, ’my_var’,\n  ’Mine/variable’, ’unit’, dims, c_stagger_cell_centre, \n  ’grid’, array, subtype_field, subarray_field)\nENDIF\n```\n\n## Cent Spec\n\nextract the central ey and save to sdf by subroutine **sdf_write_plain_variable(...)**\n"}]